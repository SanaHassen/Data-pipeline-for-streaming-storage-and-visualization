version: '3'

services:
  zookeeper:
    image: wurstmeister/zookeeper:3.4.6
    ports:
      - "2181:2181"

  kafka:
    image: wurstmeister/kafka:2.12-2.7.0
    ports:
      - "9092:9092"
    expose:
      - "9093"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka:9093,OUTSIDE://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_LISTENERS: INSIDE://0.0.0.0:9093,OUTSIDE://0.0.0.0:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock

  spark:
    image: bitnami/spark:3.0.1
    environment:
      - SPARK_MODE=master
    ports:
      - "8080:8080"
      - "7077:7077"

  hdfs-namenode:
    image: sequenceiq/hadoop-docker:2.7.1
    command: namenode
    ports:
      - "50070:50070"
    expose:
      - "50075"

  hdfs-datanode:
    image: sequenceiq/hadoop-docker:2.7.1
    command: datanode
    links:
      - hdfs-namenode
    volumes:
      - /var/hdfs/data
    expose:
      - "50010"
      - "50020"
      - "50090"
      - "50070"
      - "50075"

  streaming-app:
    image: streaming-app
    command: spark-submit --master spark://spark:7077 /opt/bitnami/spark/app.py
    volumes:
      - .:/opt/bitnami/spark
    depends_on:
      - spark
    networks:
      - default


  # New service for the dashboard
  dashboard:
    build: ./dashboard  # Path to the directory containing your dashboard code
    ports:
      - "8050:8050"  # Assuming Dash runs on port 8050
    volumes:
      - .:/opt/bitnami/spark
    depends_on:
      - spark
    networks:
      - default

networks:
  default:
    external:
      name: bridge
